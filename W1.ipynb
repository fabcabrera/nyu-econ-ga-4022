{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Data and computation 2</center>\n",
    "### <center>Alfred Galichon (NYU)</center>\n",
    "## <center>Week 1: logistic regression and generalized linear models</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Savage, L. (1951). The theory of statistical decision. JASA.\n",
    "* Bonnet, Fougère, Galichon, Poulhès (2021). Minimax estimation of hedonic models. Preprint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the libraries\n",
    "\n",
    "First, let's load the libraries we shall need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/Users/fabrizio/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#pip install gurobipy\n",
    "#!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as spr\n",
    "from scipy import optimize, special\n",
    "import gurobipy as grb\n",
    "from sklearn import linear_model\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our data\n",
    "We will go back to the dataset of Greene and Hensher (1997). As a reminder, 210 individuals are surveyed about their choice of travel mode between Sydney, Canberra and Melbourne, and the various costs (time and money) associated with each alternative. Therefore there are 840 = 4 x 210 observations, which we can stack into `travelmodedataset` a 3 dimensional array whose dimensions are mode,individual,dummy for choice+covariates.\n",
    "\n",
    "Let's load the dataset and take a first glance at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individual</th>\n",
       "      <th>mode</th>\n",
       "      <th>choice</th>\n",
       "      <th>wait</th>\n",
       "      <th>vcost</th>\n",
       "      <th>travel</th>\n",
       "      <th>gcost</th>\n",
       "      <th>income</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>air</td>\n",
       "      <td>no</td>\n",
       "      <td>69</td>\n",
       "      <td>59</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>no</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>372</td>\n",
       "      <td>71</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bus</td>\n",
       "      <td>no</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>417</td>\n",
       "      <td>70</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>car</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>air</td>\n",
       "      <td>no</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   individual   mode choice  wait  vcost  travel  gcost  income  size\n",
       "0           1    air     no    69     59     100     70      35     1\n",
       "1           1  train     no    34     31     372     71      35     1\n",
       "2           1    bus     no    35     25     417     70      35     1\n",
       "3           1    car    yes     0     10     180     30      35     1\n",
       "4           2    air     no    64     58      68     68      30     2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thepath = 'https://raw.githubusercontent.com/math-econ-code/mec_optim_2021-01/master/data_mec_optim/demand_travelmode/'\n",
    "travelmode =  pd.read_csv(thepath+'travelmodedata.csv')\n",
    "travelmode.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM to estimate discrete choice models\n",
    "\n",
    "## Estimation with observed heterogeneity\n",
    "\n",
    "We assume that we observe individual characteristics that are relevant for individual choices, that is $U_{iy}=\\sum_k \\Phi_{iyk} \\beta_k$, or in matrix form<br>\n",
    "$U = \\Phi \\beta,$<br>\n",
    "where $\\beta\\in\\mathbb{R}^{p}$ is a parameter, and $\\Phi$ is a $\\left(\\left\\vert \\mathcal{I}\\left\\vert\\right\\vert\\mathcal{Y}\\right\\vert \\right) \\times p$ matrix.\n",
    "\n",
    "Assume $u_{iy}=U_{iy} + \\varepsilon _{iy}= \\sum_{k}\\Phi _{iyk} \\beta _{k}+\\varepsilon _{iy}$.\n",
    "\n",
    "Let $\\hat{\\mu}_{iy}$ be the indicator that $i$ chooses alternative $y$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `discreteChoicePb` class where we store that data. An arc $a$ is a pair $iy$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteChoicePb():\n",
    "    def __init__(self,Φ_i_y_k, μhat_i_y):\n",
    "        self.nbi,self.nby,self.nbk = Φ_i_y_k.shape\n",
    "        self.nba = self.nbi * self.nby\n",
    "        self.Φ_a_k = Φ_i_y_k.reshape((self.nba,-1))\n",
    "        self.μhat_a = μhat_i_y.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build an object `travelEx` based on our travel data and a parametric model where the regressors are `travel`, `-travel*income` and `gcost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_travel_data():\n",
    "    μhat_a = np.where(travelmode['choice'] =='yes' , 1, 0)\n",
    "    #nobs,ncols = travelmode.shape\n",
    "    nby = travelmode['mode'].nunique()\n",
    "    nbi = travelmode.shape[0] // nby\n",
    "    covariates = travelmode[['travel', 'income', 'gcost']].values\n",
    "    Φ_a_k = np.column_stack([ covariates[:,0] , - (covariates[:,0] * covariates[:,1] ), - covariates[:,2] ])\n",
    "    _,nbk = Φ_a_k.shape \n",
    "    Φbar_k = Φ_a_k.mean(axis = 0)\n",
    "    Φstdev_k = Φ_a_k.std(axis = 0, ddof = 1)\n",
    "    Φ_i_y_k = ((Φ_a_k - Φbar_k[None,:]) / Φstdev_k[None,:]).reshape((nbi,nby,nbk)) # this is the gradient\n",
    "    return DiscreteChoicePb(Φ_i_y_k,μhat_a)\n",
    "\n",
    "travelEx = prepare_travel_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood estimation\n",
    "\n",
    "The probability $\\mu_{iy}$ that individual $i$ chooses alternative $y$ is given by $\\partial G_i / \\partial U_y (\\Phi \\beta)$. \n",
    "\n",
    "\n",
    "The log-likelihood function is given by\n",
    "\n",
    "$\n",
    "l\\left(  \\beta\\right)  =\\sum_{y}\\hat{\\mu}_{iy}\\log \\mu_{iy}\\left(\\Phi \\beta\\right) = \\sum_{y}\\hat{\\mu}_{iy}\\log  \n",
    "\\frac {\\partial G_i}  {\\partial U_y} (\\Phi \\beta)\n",
    "$\n",
    "\n",
    "A common estimation method of $\\beta$ is by maximum likelihood: $\\max_{\\beta}l\\left(  \\beta\\right) $; MLE is statistically efficient; the problem is that the problem is not guaranteed to be convex, so there may be computational difficulties (e.g. local optima).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLE, logit case\n",
    "\n",
    "In the logit case, the log-likelihood associated with observation $i\\in\\mathcal{I}$ is\n",
    "\n",
    "$\n",
    "l_{i}\\left( \\beta \\right) =\\sum_{y\\in \\mathcal{Y}}\\hat{\\mu}_{iy}\\left( \\Phi\n",
    "\\beta \\right) _{iy}-\\log \\sum_{y\\in \\mathcal{Y}}\\exp \\left( \\Phi \\beta\n",
    "\\right) _{iy}$\n",
    "\n",
    "and the max-likelihood rewrites as\n",
    "\n",
    "$\\max_{\\beta }\\left\\{ \\sum_{i\\in \\mathcal{I},y\\in \\mathcal{Y}}\\hat{\\mu}%\n",
    "_{iy}\\left( \\Phi \\beta \\right) _{iy}-\\sum_{i\\in \\mathcal{I}}\\log \\sum_{y\\in \n",
    "\\mathcal{Y}}\\exp \\left( \\Phi \\beta \\right) _{iy}\\right\\}$\n",
    "\n",
    "so that the max-likehood boils down to\n",
    "\n",
    "\\begin{align*}\n",
    "\\max_{\\beta}\\left\\{  \\hat{\\mu}^{\\intercal} \\Phi \\beta- \\sum_i G_i\\left( \\Phi \\beta\\right)\\right\\}\n",
    "\\end{align*}\n",
    "\n",
    "whose value is the Legendre-Fenchel transform of $\\beta\\rightarrow \\sum_i G_i\\left( \\Phi \\beta\\right)$ evaluated at $\\Phi ^{^{\\intercal}}\\hat{\\mu}$.\n",
    "\n",
    "Note that the vector $\\Phi^{^{\\intercal}}\\hat{\\mu}$ is the vector of empirical moments, which is a sufficient statistics in the logit model.\n",
    "\n",
    "As a result, in the logit case, the MLE is a convex optimization problem, and it is therefore both statistically efficient and computationally efficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moment estimation\n",
    "\n",
    "The previous remark will inspire an alternative procedure based on the moments statistics $\\Phi^{^{\\intercal}}\\hat{\\mu}$.\n",
    "\n",
    "The social welfare is given in general by $W\\left(  \\beta\\right) =\\sum_i G_i\\left(  \\Phi\\beta\\right)  $. One has <br>$\\partial_{\\beta^{k}}W\\left(\\beta\\right)  =\\sum_{iy} \\frac {\\partial G_i} {\\partial U_y}(\\Phi\\beta) \\Phi_{yik}$, that is \n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla W\\left(  \\beta\\right)  = \\Phi^{\\intercal}\\nabla G_i\\left(  \\Phi\\beta\\right)  ,\n",
    "\\end{align*}\n",
    "\n",
    "which is the vector of predicted moments.\n",
    "\n",
    "Therefore the program\n",
    "\n",
    "$\\max_{\\beta }\\left\\{ \\hat{\\mu}^{\\top }\\Phi \\beta -\\sum_{i\\in \\mathcal{I}%\n",
    "}G\\left( \\left( \\Phi \\beta \\right) _{i.}\\right) \\right\\} ,$\n",
    "\n",
    "(where G is the Emax operator associated with the distribution of the random utility), picks up the parameter $\\beta$ which matches the empirical moments $\\Phi^{^{\\intercal}}\\hat{q}$ with the predicted ones $\\nabla W\\left(\\beta\\right)  $. This procedure is not statistically efficient, but is computationally efficient becauses it arises as a convex optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DiscreteChoicePb class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiscreteChoicePb_mle_diy(self):\n",
    "    def minus_log_likelihood(β_k, σ = 1):\n",
    "        Φβ_i_y = (self.Φ_a_k.dot(β_k)).reshape((-1,self.nby)) \n",
    "        maxΦβ_i = Φβ_i_y.max(axis = 1)\n",
    "        d_i = np.sum(np.exp((Φβ_i_y -maxΦβ_i[:,None])/σ ), axis = 1)\n",
    "        return - ((Φβ_i_y.flatten()*self.μhat_a).sum() / σ  -  (maxΦβ_i / σ + np.log(d_i)).sum())\n",
    "\n",
    "    def grad_minus_log_likelihood(β_k, σ = 1):\n",
    "        Φβ_i_y = (self.Φ_a_k.dot(β_k)).reshape((-1,self.nby)) \n",
    "        maxΦβ_i = Φβ_i_y.max(axis = 1)\n",
    "        d_i = np.sum(np.exp((Φβ_i_y - maxΦβ_i[:,None] )/σ ), axis = 1)\n",
    "        μβ_iy = (np.exp((Φβ_i_y - maxΦβ_i[:,None] )/σ ) / d_i[:,None]).flatten()\n",
    "        return  - ((self.μhat_a - μβ_iy).reshape((1,-1)) @ self.Φ_a_k).flatten()\n",
    "\n",
    "    βtilde0_k = np.zeros(self.nbk)\n",
    "    res = optimize.minimize(minus_log_likelihood,method = 'CG',jac = grad_minus_log_likelihood, x0 = βtilde0_k )\n",
    "    βtilde_k = res['x']\n",
    "    print(-minus_log_likelihood (βtilde_k))\n",
    "    return βtilde_k[:-1] / βtilde_k[-1],  1 / βtilde_k[-1], - res['fun']  # this is the Jacobian\n",
    "\n",
    "DiscreteChoicePb.mle_diy = DiscreteChoicePb_mle_diy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-277.7052141445853\n",
      "DIY approach. βmle_k =  [0.33826733 0.85179311] ; Tmle =  1.8162760082307419  ; ll= -277.7052141445853 .\n"
     ]
    }
   ],
   "source": [
    "βmle_k,Tmle,llmle = travelEx.mle_diy()\n",
    "print('DIY approach. βmle_k = ',βmle_k,'; Tmle = ',Tmle, ' ; ll=',llmle,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation as a Poisson regression using GLM in scikit-learn\n",
    "\n",
    "As a reminder, this can be computed as \n",
    "\\begin{align*}\n",
    "\\min_{\\beta,u} \\left\\{ \\sum_{iy} \\hat{\\mu}_{iy} \\left(   \\Phi\\beta - (I_\\mathcal{I} \\otimes 1_\\mathcal{Y}) u \\right)  _{iy} - \\sum_{iy} \\exp\\left(  \\left(  \\Phi\\beta - (I_\\mathcal{I} \\otimes 1_\\mathcal{Y}) u \\right) _{iy} \\right)  \\right\\}\n",
    "\\end{align*}\n",
    "\n",
    "which leads to the following call to `scikit-learn`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiscreteChoicePb_mle_glm(self, max_iter = 1000, tol=0.0001):\n",
    "    poisson = linear_model.PoissonRegressor(alpha = 0, fit_intercept=False,max_iter= max_iter, tol = tol)\n",
    "    X_a_l = spr.hstack([self.Φ_a_k, -spr.kron(spr.identity(self.nbi), np.ones((self.nby,1)))])\n",
    "    poisson.fit(X_a_l, self.μhat_a)\n",
    "    val =  self.μhat_a @ X_a_l @ poisson.coef_ - (np.exp(X_a_l @ poisson.coef_)).sum() + self.nbi\n",
    "    return poisson.coef_[:self.nbk-1] / poisson.coef_[self.nbk-1],1 / poisson.coef_[self.nbk-1], val\n",
    "\n",
    "DiscreteChoicePb.mle_glm = DiscreteChoicePb_mle_glm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify that both approaches are indeed equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLM approach. βmle_k =  [0.33826961 0.8517962 ] ; Tmle =  1.816271931055784  ; ll= -277.7052141450895 .\n",
      "DIY approach. βmle_k =  [0.33826733 0.85179311] ; Tmle =  1.8162760082307419  ; ll= -277.7052141445853 .\n"
     ]
    }
   ],
   "source": [
    "βmleglm_k,Tmleglm,llmleglm = travelEx.mle_glm(max_iter = 10000, tol = 1e-9)\n",
    "print('GLM approach. βmle_k = ',βmleglm_k,'; Tmle = ',Tmleglm, ' ; ll=',llmleglm,'.')\n",
    "print('DIY approach. βmle_k = ',βmle_k,'; Tmle = ',Tmle, ' ; ll=',llmle,'.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31582b9feba862c420bc95ad7fac43fb721c474490d1710b4e50ac63470f9531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
